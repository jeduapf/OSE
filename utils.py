"""Energy Dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FDY-T0jv5hmTyrXNrv91GBcezX1Magdd

# Energy Dataset
***José Eduardo ALVES***


*   Small code to get data from [World in Data](https://ourworldindata.org/)
*   Their github is [World in Data](https://github.com/owid)
*   The HDI data comes from [Human Development Reports](https://hdr.undp.org/data-center/documentation-and-downloads)

## Imports
"""

import plotly.express as px
import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import requests
import json
import plotly.graph_objects as go
from scipy.stats import chi2
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
import os
import io
import re
import chardet
from sklearn.linear_model import LinearRegression

warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=UserWarning, message=".*Boolean Series key will be reindexed.*")

"""## Functions"""

def fill_population_with_regression(df, country):
    """
    Uses linear regression to fill zero values in the 'population' column for a given country.

    Parameters:
    - df (pd.DataFrame): The original DataFrame containing 'country', 'year', and 'population'.
    - country (str): The country to process.

    Returns:
    - None (modifies the DataFrame in-place)
    """
    # Filter data for the specific country
    country_df = df[df['country'] == country].fillna(0).copy()

    # Extract years and population values
    years = country_df['year'].values.reshape(-1, 1)
    population = country_df['population'].values

    # Identify zero values
    zero_mask = (population == 0)

    # Train regression only on non-zero values
    valid_mask = ~zero_mask  # Mask where population is NOT zero
    X_train = years[valid_mask]
    y_train = population[valid_mask]

    # Check if there's enough data to fit a regression model
    if len(X_train) < 2:
        print(f"Not enough valid data to train regression for {country}. Skipping...")

    # Train linear regression model
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Predict missing values
    X_predict = years[zero_mask]  # Years where population is zero
    predicted_values = model.predict(X_predict)

    # Replace zero values with predicted ones
    country_df.loc[zero_mask, 'population'] = predicted_values

    # Update the original DataFrame
    df.loc[df['country'] == country, 'population'] = country_df['population']

    return df

def replace_country_names(df, imf_country_names):

    # Create a copy to avoid modifying the original DataFrame
    new_df = df.copy()

    # Use the replace method with the provided mapping
    new_df['country'] = new_df['Country'].replace(imf_country_names)
    new_df = new_df.drop('Country', axis=1)

    return new_df

# TODO: For Oscar to check if there is anything missing
def imf_country_names():
    imf_names ={
        'Aruba': None,
        'Brunei Darussalam':  'Brunei',
        'Cabo Verde':  'Cape Verde',
        'Czech Republic':  'Czechia',
        "Côte d'Ivoire": "Cote d'Ivoire" ,
        'Democratic Republic of the Congo':  'Democratic Republic of Congo',
        'Hong Kong SAR':  'Hong Kong',
        'Islamic Republic of Iran':  'Iran',
        'Korea':  'South Korea',
        'Kosovo': None,
        'Kyrgyz Republic':  'Kyrgyzstan',
        'Lao P.D.R.':  'Laos',
        'Macao SAR': None,
        'Micronesia':  'Micronesia (country)',
        'Moldova':  'Moldova (Republic of)',
        'Nauru': None,
        'Puerto Rico': None,
        'Republic of Congo':  'Congo',
        'Slovak Republic':  'Slovakia',
        'Somalia': None,
        'St. Kitts and Nevis':  'Saint Kitts and Nevis',
        'St. Lucia':  'Saint Lucia',
        'St. Vincent and the Grenadines':  'Saint Vincent and the Grenadines',
        'São Tomé and Príncipe':  'Sao Tome and Principe',
        'Taiwan Province of China': None,
        'The Bahamas':  'Bahamas',
        'The Gambia':  'Gambia',
        'Timor-Leste':  'East Timor',
        'Türkiye':  'Turkey',
        'West Bank and Gaza':None,
        }
    return imf_names

def get_imf_gdp_projection_for_my_friend_Oscar(encodage = None, url = "https://www.imf.org/-/media/Files/Publications/WEO/WEO-Database/2024/October/WEOOct2024all.ashx"):

    # Get data
    response = requests.get(url)
    xls_file = io.BytesIO(response.content)

    # preciso disso pq ta encodado de um jeito bizarro
    if encodage == None:
        result = chardet.detect(xls_file.read())

        xls_file.seek(0)
        decoded_text = xls_file.read().decode(result['encoding']) 
    else:
        decoded_text = xls_file.read().decode(encodage)

    # Vou re-encodar esta ***** em utf-8
    csv_filename = "tab_separated_file.csv"
    with open(csv_filename, "w", encoding='utf-8') as csv_file:
        csv_file.write(decoded_text)

    df = pd.read_csv(csv_filename, sep='\t', encoding='utf-8')

    # convet country names to match with our own table
    df = replace_country_names(df, imf_country_names())

    # Get only important Data from it
    df = df[['country', 'Subject Descriptor', 'Subject Notes', 'Units', 'Scale', 'Country/Series-specific Notes'] + list(str(i) for i in range(1980,2030,1))]

    string = "Values are based upon GDP in national currency converted to U.S. dollars using market exchange rates (yearly average). Exchange rate projections are provided by country economists for the group of other emerging market and developing countries. Exchanges rates for advanced economies are established in the WEO assumptions for each WEO exercise. Expenditure-based GDP is total final expenditures at purchasers' prices (including the f.o.b. value of exports of goods and services), less the f.o.b. value of imports of goods and services. [SNA 1993]"

    gdps = df[df['Subject Notes'] == string].drop(['Units', 'Scale', 'Country/Series-specific Notes', 'Subject Notes', 'Subject Descriptor'], axis=1)

    # Melt the DataFrame to reshape it
    melted_df = pd.melt(gdps, id_vars=['country'], var_name='year', value_name='gdp')

    # Optionally, sort by country and year if needed
    melted_df['year'] = melted_df['year'].astype(int)  # Ensure year is an integer type for sorting
    melted_df = melted_df.sort_values(by=['country', 'year'])

    cleaned_df = melted_df.dropna(subset=['country'])

    return df, cleaned_df

def add_imf_gdp_projections(enormous_super_big_complete_table, melted):
    # Years of the projection
    years_to_add = list(range(np.max(enormous_super_big_complete_table.year) +1, np.max(melted.year)+1))

    # Convert to dollars
    melted['gdp'] = melted['gdp'].apply(lambda x: x.replace(',', '') if isinstance(x, str) else x).astype(float)*10**9

    gdp_projections = melted[melted['year'].isin(years_to_add)]

    # Append the new rows to the existing DataFrame
    kk = pd.concat([enormous_super_big_complete_table, gdp_projections], ignore_index=True)

    # Sort the DataFrame by country and year
    kk = kk.sort_values(by=['country', 'year'])
    kk['gdp_pct_change'] = kk['gdp'].pct_change()*100

    return kk

def use_imf_data(enormous_super_big_complete_table, melted):
    countries_in_melted = list(set(melted.country))

    for index, row in enormous_super_big_complete_table.iterrows():

        # If there is no gdp data in the dataframe
        if (row['gdp'] == 0):
            if (row['country'] in countries_in_melted):
                melted_gdp = melted[(melted.country == row.country) & (melted.year == row.year)]

                # Update table
                enormous_super_big_complete_table.loc[index, 'gdp'] = melted_gdp['gdp'].values[0]

    gdp_pct_change_by_country = enormous_super_big_complete_table.groupby('country')['gdp'].pct_change()

    enormous_super_big_complete_table['gdp_pct_change'] = gdp_pct_change_by_country*100

    return enormous_super_big_complete_table

def create_folder_if_not_exists(folder_path):
  """Creates a folder if it doesn't exist.

  Args:
      folder_path: The path to the folder.
  """
  if not os.path.exists(folder_path):
    os.makedirs(folder_path)

def download_data(JSON_DATA = "https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.json", CSV_DESCRIPTION = 'https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-codebook.csv'):
  """
  Downloads CO2 emission data from OWID and its description.

  Args:
      JSON_DATA (str, optional): URL to the JSON data file.
                                  Defaults to "https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.json".
      CSV_DESCRIPTION (str, optional): URL to the CSV description file.
                                        Defaults to 'https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-codebook.csv'.

  Returns:
      tuple: A tuple containing the downloaded JSON data (as a Python dictionary) and a Pandas DataFrame representing the CSV description.
  """
  # Download the JSON file
  response = requests.get(JSON_DATA)
  data = json.loads(response.text)

  # Download the CSV file from GitHub
  df = pd.read_csv(CSV_DESCRIPTION)

  # Create a dictionary to store the key-description pairs
  key_description_dict = {}

  # Iterate through the DataFrame and populate the dictionary
  for index, row in df.iterrows():
    key_description_dict[row['column']] = row['description']

  df_dict = {}
  for country in data.keys():
    df_dict[country] = pd.DataFrame(data[country]['data'])

  return df_dict, key_description_dict

def full_outer_join_datasets(df_dict_co2, df_dict_elec, ON = ['year']):
    """
    Performs a full outer join of two datasets based on 'country', 'year', and 'iso_code'.

    Args:
        df_dict_co2: A dictionary of dataframes, where keys are country names and values are dataframes with CO2 data.
        df_dict_elec: A dictionary of dataframes, where keys are country names and values are dataframes with electricity data.
        ON: A list of columns to use for the join operation. Defaults to ['country', 'year', 'iso_code'].

    Returns:
        A pandas DataFrame representing the full outer join of the two datasets.
        Returns None if any error occurs during the process.
    """

    try:
        ultra_duper_super_big_list = []
        went_well = []
        didnt_go_well = []

        for country in df_dict_co2:
          if country in df_dict_elec:

              # Get the dataframes of each country
              df1 = df_dict_co2.get(country)
              df2 = df_dict_elec.get(country)

              # Perform a full outer join (SQL way)
              merged_df = pd.merge(df1, df2, on=ON, how='outer', suffixes=('_co2', '_elec'))
              merged_df['country'] = country
              ultra_duper_super_big_list.append(merged_df)

              went_well.append(country)
          else:
              # print(f"Warning: Country '{country}' found in df_dict_co2 but not df_dict_elec.")
              didnt_go_well.append(country)

        ultra_duper_super_big_df = pd.concat(ultra_duper_super_big_list, ignore_index=True, join='outer')

        return ultra_duper_super_big_df, went_well, didnt_go_well

    except Exception as e:
        print(f"An error occurred: {e}")
        return None

def verify_columns(df, col1, col2, name, epsilon=1e-5):
    """
    Verifies if two columns have approximately the same values within a given epsilon,
    creates a column 'equal' with the non-NaN value from either column if values are close or either is NaN,
    and removes 'is_close' and 'difference' columns before returning the DataFrame.

    Parameters:
        df (pd.DataFrame): The input DataFrame.
        col1 (str): The name of the first column.
        col2 (str): The name of the second column.
        epsilon (float): The tolerance level for the difference. Default is 1e-5.

    Returns:
        pd.DataFrame: The modified DataFrame with only the new 'equal' column added.
    """

    # Create columns D and diff
    df[name] = np.nan  # Initialize with NaN
    df[name + '_diff'] = False #Initialize diff with False

    # Apply logic without using a loop
    df[name] = np.where(df[col1].isna() & df[col2].isna(),
                                np.nan,
                                np.where(df[col1].isna(),
                                        df[col2],
                                        np.where(df[col2].isna(),
                                                df[col1],
                                                (df[col1] + df[col2]) / 2)))


    df[name + '_diff'] = np.where((~df[col1].isna() & ~df[col2].isna()) & (abs(df[col1] - df[col2]) > 0.1), True, False)


    # Drop 'is_close' and 'difference' columns before returning
    df = df.drop(columns=[col1, col2])

    return df

def get_columns(df, columns_to_get = ['hdi']):
    new_dataframe = []
    for col in df.columns:
        name = '_'.join(col.split('_')[:-1])
        year = col.split('_')[-1]
        if name in columns_to_get:
            # Create a new DataFrame with the desired columns
            aux = pd.DataFrame({'year': year, 'country': df['country'], 'iso3': df['iso3'], 'region': df['region'], name: df[col]})
            aux = aux.astype({
                'year': 'int',
                'country': 'string',
                'iso3': 'string',
                'region': 'string',
                name: 'float'
            })
            new_dataframe.append(aux)

    # Concatenate the new DataFrames into a single DataFrame
    final_df = pd.concat(new_dataframe, ignore_index=True)
    return final_df

def organize_hdi(columns_to_get = ['hdi']):

    df = download_hdi()

    return get_columns(df, columns_to_get)

def download_hdi(url="http://hdr.undp.org/sites/default/files/2021-22_HDR/HDR21-22_Composite_indices_complete_time_series.csv"):
    """Downloads the HDI dataset from the provided URL, handling potential errors.

    Args:
        url (str): The URL of the HDI dataset. Defaults to the UNDP website.

    Returns:
        pd.DataFrame: A pandas DataFrame containing the HDI data.
                      Returns None if the download or processing fails.
    """
    try:
        # Use requests to get the content, handling potential connection errors
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for bad status codes

        # Read the CSV data from the response content using io.StringIO
        df = pd.read_csv(io.StringIO(response.text))

    except requests.exceptions.RequestException as e:
        print(f"Error downloading HDI data: {e}")
        return None  # Return None to indicate download failure
    except pd.errors.ParserError as e:
        print(f"Error parsing HDI data: {e}")
        return None  # Return None to indicate processing failure

    return df # Return the DataFrame if successful

def pipeline(df_dict_co2, df_dict_elec, cols, columns_to_get = ['hdi']):

    final2hdi = {
    'Nigeria': 'Nigeria',
    'Vietnam': 'Viet Nam',
    'United States': 'United States',
    'China': 'China',
    'Uzbekistan': 'Uzbekistan',
    'Palestine': 'Palestine, State of',
    'Micronesia (country)': 'Micronesia (Federated States of)',
    'Yemen': 'Yemen',
    'Georgia': 'Georgia',
    'El Salvador': 'El Salvador',
    'Slovenia': 'Slovenia',
    'Equatorial Guinea': 'Equatorial Guinea',
    'Sweden': 'Sweden',
    'Egypt': 'Egypt',
    'Cambodia': 'Cambodia',
    'Iceland': 'Iceland',
    'Macao': None,
    'Philippines': 'Philippines',
    'Togo': 'Togo',
    'Uganda': 'Uganda',
    'Guatemala': 'Guatemala',
    'Kazakhstan': 'Kazakhstan',
    'Montenegro': 'Montenegro',
    'Liberia': 'Liberia',
    'Burundi': 'Burundi',
    'Guyana': 'Guyana',
    'Switzerland': 'Switzerland',
    'United Kingdom': 'United Kingdom',
    'Barbados': 'Barbados',
    'Angola': 'Angola',
    'Iran': 'Iran (Islamic Republic of)',
    'Kyrgyzstan': 'Kyrgyzstan',
    'Niger': 'Niger',
    'Oceania': None,
    'Lithuania': 'Lithuania',
    'Comoros': 'Comoros',
    'Guinea': 'Guinea',
    'Serbia': 'Serbia',
    'Sierra Leone': 'Sierra Leone',
    'Ukraine': 'Ukraine',
    'Venezuela': 'Venezuela (Bolivarian Republic of)',
    'Dominican Republic': 'Dominican Republic',
    'India': 'India',
    'Bosnia and Herzegovina': 'Bosnia and Herzegovina',
    'Bolivia': 'Bolivia (Plurinational State of)',
    'Congo': 'Congo',
    'Guinea-Bissau': 'Guinea-Bissau',
    'Cyprus': 'Cyprus',
    'Honduras': 'Honduras',
    'Malawi': 'Malawi',
    'Panama': 'Panama',
    'Syria': 'Syrian Arab Republic',
    'Kiribati': 'Kiribati',
    'Mozambique': 'Mozambique',
    'Albania': 'Albania',
    'Democratic Republic of Congo': 'Congo (Democratic Republic of the)',
    'Nicaragua': 'Nicaragua',
    'Argentina': 'Argentina',
    'Trinidad and Tobago': 'Trinidad and Tobago',
    'Nauru': 'Nauru',
    'Denmark': 'Denmark',
    'Brazil': 'Brazil',
    'Kuwait': 'Kuwait',
    'Russia': 'Russian Federation',
    'Mali': 'Mali',
    'Armenia': 'Armenia',
    'Bahamas': 'Bahamas',
    'Costa Rica': 'Costa Rica',
    'Tajikistan': 'Tajikistan',
    'Zimbabwe': 'Zimbabwe',
    'Canada': 'Canada',
    'World': None,
    'Chile': 'Chile',
    'Portugal': 'Portugal',
    'European Union (27)': None,
    'Peru': 'Peru',
    'South Sudan': 'South Sudan',
    'Turks and Caicos Islands': None,
    'Sri Lanka': 'Sri Lanka',
    'Haiti': 'Haiti',
    'Rwanda': 'Rwanda',
    'Mauritania': 'Mauritania',
    'Luxembourg': 'Luxembourg',
    'Tanzania': 'Tanzania (United Republic of)',
    'Mongolia': 'Mongolia',
    'Norway': 'Norway',
    'Romania': 'Romania',
    'Brunei': 'Brunei Darussalam',
    "Cote d'Ivoire": "CÃ´te d'Ivoire",
    'Jamaica': 'Jamaica',
    'Latvia': 'Latvia',
    'Asia': None,
    'East Timor': 'Timor-Leste',
    'France': 'France',
    'Finland': 'Finland',
    'Montserrat': None,
    'Bermuda': None,
    'Burkina Faso': 'Burkina Faso',
    'Hong Kong': 'Hong Kong, China (SAR)',
    'Saint Lucia': 'Saint Lucia',
    'Ghana': 'Ghana',
    'Saint Vincent and the Grenadines': 'Saint Vincent and the Grenadines',
    'Zambia': 'Zambia',
    'North Macedonia': 'North Macedonia',
    'Libya': 'Libya',
    'Eritrea': 'Eritrea',
    'Nepal': 'Nepal',
    'Turkey': 'Turkey',
    'Gabon': 'Gabon',
    'Bhutan': 'Bhutan',
    'New Caledonia': None,
    'Moldova': 'Moldova (Republic of)',
    'Aruba': None,
    'Kenya': 'Kenya',
    'Estonia': 'Estonia',
    'Myanmar': 'Myanmar',
    'Ecuador': 'Ecuador',
    'Papua New Guinea': 'Papua New Guinea',
    'Malaysia': 'Malaysia',
    'French Polynesia': None,
    'Saint Pierre and Miquelon': None,
    'Namibia': 'Namibia',
    'Poland': 'Poland',
    'Cameroon': 'Cameroon',
    'Saint Kitts and Nevis': 'Saint Kitts and Nevis',
    'Upper-middle-income countries': None,
    'Croatia': 'Croatia',
    'Antigua and Barbuda': 'Antigua and Barbuda',
    'North America': None,
    'Eswatini': 'Eswatini (Kingdom of)',
    'Hungary': 'Hungary',
    'Greece': 'Greece',
    'Czechia': 'Czechia',
    'Grenada': 'Grenada',
    'Ethiopia': 'Ethiopia',
    'Morocco': 'Morocco',
    'South America': None,
    'Jordan': 'Jordan',
    'Somalia': 'Somalia',
    'Botswana': 'Botswana',
    'Italy': 'Italy',
    'Cuba': 'Cuba',
    'Cape Verde': 'Cabo Verde',
    'Fiji': 'Fiji',
    'Afghanistan': 'Afghanistan',
    'Bulgaria': 'Bulgaria',
    'Central African Republic': 'Central African Republic',
    'Suriname': 'Suriname',
    'Senegal': 'Senegal',
    'Lesotho': 'Lesotho',
    'Qatar': 'Qatar',
    'Mexico': 'Mexico',
    'Tonga': 'Tonga',
    'Malta': 'Malta',
    'Low-income countries': None,
    'Dominica': 'Dominica',
    'Lower-middle-income countries': None,
    'Samoa': 'Samoa',
    'Lebanon': 'Lebanon',
    'Chad': 'Chad',
    'Australia': 'Australia',
    'Curacao': None,
    'Austria': 'Austria',
    'Faroe Islands': None,
    'Bangladesh': 'Bangladesh',
    'Europe': None,
    'Spain': 'Spain',
    'Algeria': 'Algeria',
    'Sao Tome and Principe': 'Sao Tome and Principe',
    'Tunisia': 'Tunisia',
    'Belarus': 'Belarus',
    'Oman': 'Oman',
    'Pakistan': 'Pakistan',
    'Djibouti': 'Djibouti',
    'Colombia': 'Colombia',
    'South Korea': 'Korea (Republic of)',
    'Saudi Arabia': 'Saudi Arabia',
    'Thailand': 'Thailand',
    'Vanuatu': 'Vanuatu',
    'Belgium': 'Belgium',
    'Bahrain': 'Bahrain',
    'Benin': 'Benin',
    'Gambia': 'Gambia',
    'Iraq': 'Iraq',
    'Turkmenistan': 'Turkmenistan',
    'British Virgin Islands': None,
    'Ireland': 'Ireland',
    'Madagascar': 'Madagascar',
    'Indonesia': 'Indonesia',
    'Antarctica': None,
    'New Zealand': 'New Zealand',
    'North Korea': "Korea (Democratic People\'s Rep. of)",
    'Laos': "Lao People\'s Democratic Republic",
    'Seychelles': 'Seychelles',
    'Mauritius': 'Mauritius',
    'Germany': 'Germany',
    'Cook Islands': None,
    'Paraguay': 'Paraguay',
    'Sudan': 'Sudan',
    'Tuvalu': 'Tuvalu',
    'Solomon Islands': 'Solomon Islands',
    'United Arab Emirates': 'United Arab Emirates',
    'Uruguay': 'Uruguay',
    'Azerbaijan': 'Azerbaijan',
    'Kosovo': None,
    'Slovakia': 'Slovakia',
    'High-income countries': None,
    'Israel': 'Israel',
    'Taiwan': None,
    'Netherlands': 'Netherlands',
    'Japan': 'Japan',
    'Singapore': 'Singapore',
    'Belize': 'Belize',
    'Saint Helena': None,
    'Maldives': 'Maldives',
    'Niue': None,
    'South Africa': 'South Africa',
    'Africa': None,
    'Greenland': None
    }

    hdi2final = {
    'Nigeria': 'Nigeria',
    'Viet Nam': 'Vietnam',
    'United States': 'United States',
    'China': 'China',
    'Uzbekistan': 'Uzbekistan',
    'Palestine, State of': 'Palestine',
    'Micronesia (Federated States of)': 'Micronesia (country)',
    'Yemen': 'Yemen',
    'Georgia': 'Georgia',
    'El Salvador': 'El Salvador',
    'Slovenia': 'Slovenia',
    'Equatorial Guinea': 'Equatorial Guinea',
    'Sweden': 'Sweden',
    'Egypt': 'Egypt',
    'Cambodia': 'Cambodia',
    'Iceland': 'Iceland',
    "CÃ´te d'Ivoire": "Cote d'Ivoire",
    # None: ['Macao', 'Oceania', 'World', 'European Union (27)', 'Turks and Caicos Islands', 'Asia', 'Montserrat', 'Bermuda', 'New Caledonia', 'Aruba', 'French Polynesia', 'Saint Pierre and Miquelon', 'Saint Kitts and Nevis', 'Upper-middle-income countries', 'North America', 'South America', 'Cote d'Ivoire', 'Low-income countries', 'Curacao', 'Faroe Islands', 'Europe', 'British Virgin Islands', 'Antarctica', 'Cook Islands', 'Kosovo', 'High-income countries', 'Taiwan', 'Saint Helena', 'Niue', 'Africa', 'Greenland'],
    'Philippines': 'Philippines',
    'Togo': 'Togo',
    'Uganda': 'Uganda',
    'Guatemala': 'Guatemala',
    'Kazakhstan': 'Kazakhstan',
    'Montenegro': 'Montenegro',
    'Liberia': 'Liberia',
    'Burundi': 'Burundi',
    'Guyana': 'Guyana',
    'Switzerland': 'Switzerland',
    'United Kingdom': 'United Kingdom',
    'Barbados': 'Barbados',
    'Angola': 'Angola',
    'Iran (Islamic Republic of)': 'Iran',
    'Kyrgyzstan': 'Kyrgyzstan',
    'Niger': 'Niger',
    'Lithuania': 'Lithuania',
    'Comoros': 'Comoros',
    'Guinea': 'Guinea',
    'Serbia': 'Serbia',
    'Sierra Leone': 'Sierra Leone',
    'Ukraine': 'Ukraine',
    'Venezuela (Bolivarian Republic of)': 'Venezuela',
    'Dominican Republic': 'Dominican Republic',
    'India': 'India',
    'Bosnia and Herzegovina': 'Bosnia and Herzegovina',
    'Bolivia (Plurinational State of)': 'Bolivia',
    'Congo': 'Congo',
    'Guinea-Bissau': 'Guinea-Bissau',
    'Cyprus': 'Cyprus',
    'Honduras': 'Honduras',
    'Malawi': 'Malawi',
    'Panama': 'Panama',
    'Syrian Arab Republic': 'Syria',
    'Kiribati': 'Kiribati',
    'Mozambique': 'Mozambique',
    'Albania': 'Albania',
    'Congo (Democratic Republic of the)': 'Democratic Republic of Congo',
    'Nicaragua': 'Nicaragua',
    'Argentina': 'Argentina',
    'Trinidad and Tobago': 'Trinidad and Tobago',
    'Nauru': 'Nauru',
    'Denmark': 'Denmark',
    'Brazil': 'Brazil',
    'Kuwait': 'Kuwait',
    'Russian Federation': 'Russia',
    'Mali': 'Mali',
    'Armenia': 'Armenia',
    'Bahamas': 'Bahamas',
    'Costa Rica': 'Costa Rica',
    'Tajikistan': 'Tajikistan',
    'Zimbabwe': 'Zimbabwe',
    'Canada': 'Canada',
    'Chile': 'Chile',
    'Portugal': 'Portugal',
    'Peru': 'Peru',
    'South Sudan': 'South Sudan',
    'Sri Lanka': 'Sri Lanka',
    'Haiti': 'Haiti',
    'Rwanda': 'Rwanda',
    'Mauritania': 'Mauritania',
    'Luxembourg': 'Luxembourg',
    'Tanzania (United Republic of)': 'Tanzania',
    'Mongolia': 'Mongolia',
    'Norway': 'Norway',
    'Romania': 'Romania',
    'Brunei Darussalam': 'Brunei',
    'Timor-Leste': 'East Timor',
    'France': 'France',
    'Finland': 'Finland',
    'Burkina Faso': 'Burkina Faso',
    'Hong Kong, China (SAR)': 'Hong Kong',
    'Saint Lucia': 'Saint Lucia',
    'Ghana': 'Ghana',
    'Saint Vincent and the Grenadines': 'Saint Vincent and the Grenadines',
    'Zambia': 'Zambia',
    'North Macedonia': 'North Macedonia',
    'Libya': 'Libya',
    'Eritrea': 'Eritrea',
    'Nepal': 'Nepal',
    'Turkey': 'Turkey',
    'Gabon': 'Gabon',
    'Bhutan': 'Bhutan',
    'Kenya': 'Kenya',
    'Estonia': 'Estonia',
    'Myanmar': 'Myanmar',
    'Ecuador': 'Ecuador',
    'Papua New Guinea': 'Papua New Guinea',
    'Malaysia': 'Malaysia',
    'Namibia': 'Namibia',
    'Poland': 'Poland',
    'Cameroon': 'Cameroon',
    'Saint Kitts and Nevis': 'Saint Kitts and Nevis',
    'Croatia': 'Croatia',
    'Antigua and Barbuda': 'Antigua and Barbuda',
    'Eswatini (Kingdom of)': 'Eswatini',
    'Hungary': 'Hungary',
    'Greece': 'Greece',
    'Czechia': 'Czechia',
    'Grenada': 'Grenada',
    'Ethiopia': 'Ethiopia',
    'Morocco': 'Morocco',
    'Jordan': 'Jordan',
    'Somalia': 'Somalia',
    'Botswana': 'Botswana',
    'Italy': 'Italy',
    'Cuba': 'Cuba',
    'Cabo Verde': 'Cape Verde',
    'Fiji': 'Fiji',
    'Afghanistan': 'Afghanistan',
    'Bulgaria': 'Bulgaria',
    'Central African Republic': 'Central African Republic',
    'Suriname': 'Suriname',
    'Senegal': 'Senegal',
    'Lesotho': 'Lesotho',
    'Qatar': 'Qatar',
    'Mexico': 'Mexico',
    'Tonga': 'Tonga',
    'Malta': 'Malta',
    'Dominica': 'Dominica',
    'Samoa': 'Samoa',
    'Lebanon': 'Lebanon',
    'Chad': 'Chad',
    'Australia': 'Australia',
    'Austria': 'Austria',
    'Bangladesh': 'Bangladesh',
    'Spain': 'Spain',
    'Algeria': 'Algeria',
    'Sao Tome and Principe': 'Sao Tome and Principe',
    'Tunisia': 'Tunisia',
    'Belarus': 'Belarus',
    'Oman': 'Oman',
    'Pakistan': 'Pakistan',
    'Djibouti': 'Djibouti',
    'Colombia': 'Colombia',
    'Korea (Republic of)': 'South Korea',
    'Saudi Arabia': 'Saudi Arabia',
    'Thailand': 'Thailand',
    'Vanuatu': 'Vanuatu',
    'Belgium': 'Belgium',
    'Bahrain': 'Bahrain',
    'Benin': 'Benin',
    'Gambia': 'Gambia',
    'Iraq': 'Iraq',
    'Turkmenistan': 'Turkmenistan',
    'Ireland': 'Ireland',
    'Madagascar': 'Madagascar',
    'Indonesia': 'Indonesia',
    'New Zealand': 'New Zealand',
    "Korea (Democratic People\'s Rep. of)": 'North Korea',
    "Lao People\'s Democratic Republic": 'Laos',
    'Seychelles': 'Seychelles',
    'Mauritius': 'Mauritius',
    'Germany': 'Germany',
    'Paraguay': 'Paraguay',
    'Sudan': 'Sudan',
    'Tuvalu': 'Tuvalu',
    'Solomon Islands': 'Solomon Islands',
    'United Arab Emirates': 'United Arab Emirates',
    'Uruguay': 'Uruguay',
    'Azerbaijan': 'Azerbaijan',
    'Slovakia': 'Slovakia',
    'Israel': 'Israel',
    'Netherlands': 'Netherlands',
    'Japan': 'Japan',
    'Singapore': 'Singapore',
    'Belize': 'Belize',
    'Maldives': 'Maldives',
    'South Africa': 'South Africa',
    }



    final_df, went_well, didnt_go_well = full_outer_join_datasets(df_dict_co2, df_dict_elec, ON = ['year'])

    final_df = verify_columns(final_df, 'gdp_co2', 'gdp_elec', 'gdp', epsilon=1e-5)

    final_df = verify_columns(final_df, 'population_co2', 'population_elec', 'population', epsilon=1e-5)

    final_df = calculate_growth_and_compare(final_df, ['gdp', 'population'])
    final_df['year'] = pd.to_numeric(final_df['year'], errors='coerce')

    hdi_df = organize_hdi(columns_to_get)

    # Correct country names to English standard
    hdi_df['country'] = hdi_df['country'].replace(hdi2final)

    enormous_super_big_complete_table = pd.merge(hdi_df, final_df, on=['year', 'country'], how='outer')

    enormous_super_big_complete_table = enormous_super_big_complete_table.sort_values('hdi', na_position='last').drop_duplicates(subset=['year', 'country', 'gdp', 'population', 'gdp_pct_change', 'population_pct_change'], keep='first')

    # # Get the list of columns to process, excluding 'hdi'
    # cols_to_fill = [col for col in enormous_super_big_complete_table.columns if col != 'hdi']

    # # Fill NaN values with 0 for the selected columns
    # enormous_super_big_complete_table[cols_to_fill] = enormous_super_big_complete_table[cols_to_fill].fillna(0)
    enormous_super_big_complete_table = enormous_super_big_complete_table[cols].fillna(0)
    enormous_super_big_complete_table.loc[enormous_super_big_complete_table['hdi'] == 0, 'hdi'] = np.nan
    enormous_super_big_complete_table = enormous_super_big_complete_table.dropna(subset=['hdi'])

    return enormous_super_big_complete_table

def calculate_consecutive_years(plot_countries):
    """Calculates consecutive years of strikes per country.
    Args:
        plot_countries (pd.DataFrame): DataFrame with 'country' and 'year' columns.
    Returns:
        dict: A dictionary where keys are countries and values are dictionaries
              containing consecutive years information.
    """
    result = {}
    for country in plot_countries['country'].unique():
        country_data = plot_countries[plot_countries['country'] == country]
        years = sorted(country_data['year'].unique())

        if not years:  # Handle cases where there are no years for the country
          continue

        consecutive_periods = []
        start_year = years[0]
        current_period = [start_year]

        for i in range(len(years) - 1):
            if years[i+1] == years[i] + 1:
                current_period.append(years[i+1])
            else:
                consecutive_periods.append({'start': start_year, 'end': years[i], 'length': len(current_period)})
                start_year = years[i+1]
                current_period = [start_year]

        consecutive_periods.append({'start': start_year, 'end': years[-1], 'length': len(current_period)})
        result[country] = consecutive_periods
    return result

def calculate_consecutive_years_from(df, start_date=2015):
    """
    Calculates the sum of strikes from a specific start date until the last year for each country.
    """
    total_strikes = {}

    for country in df['country'].unique():
      country_data = df[df['country'] == country]
      if not country_data.empty:
          country_data_sorted = country_data.sort_values('year')
          #Filter data starting from start_date
          country_data_filtered = country_data_sorted[country_data_sorted['year'] >= start_date]

          total_strikes_for_country = 0

          current_strike_start = None
          current_strike_length = 0

          for i in range (len(country_data_filtered)):
              if i > 0 and country_data_filtered['year'].iloc[i] == country_data_filtered['year'].iloc[i-1] +1:
                  current_strike_length += 1
              else:
                if current_strike_length > 0:
                    total_strikes_for_country += current_strike_length

                if i < len(country_data_filtered):
                    current_strike_start = country_data_filtered['year'].iloc[i]
                    current_strike_length = 1

          #Add the last strike if there is any
          if current_strike_length > 0:
              total_strikes_for_country += current_strike_length

          total_strikes[country] = total_strikes_for_country-1

    return total_strikes

def calculate_growth_and_compare(df, coloumns):

    for col in coloumns:
        # Calculate percentage change
        df[f'{col}_pct_change'] = df.groupby('country')[col].pct_change() * 100
        df[f'{col}_pct_change'] = df[f'{col}_pct_change'].round(2)

    return df

def string_to_integer(s):
  """Converts a string to an integer if it represents a number.

  Args:
    s: The string to convert.

  Returns:
    The integer representation of the string if it's a number,
    otherwise returns the original string.
  """
  try:
    return int(s)
  except ValueError:
    return None

def filter_df(df, YEAR, thresholds):
    original = df.copy()

    for nom, value in thresholds.items():
        if value[1] == 'bigger':
            df = df[(df[nom] > value[0]) & pd.notna(df[nom])]  # Exclude NaN values

        elif value[1] == 'smaller':
            df = df[(df[nom] < value[0]) & pd.notna(df[nom])]  # Exclude NaN values

        # print(df[[nom,'year']])
        # print()
        # print()
    df = df[df['year'] == YEAR]

    complementary_df = pd.concat([original, df]).drop_duplicates(keep=False, subset=original.columns.to_list())
    return df, complementary_df[complementary_df['year'] == YEAR]

def get_countries_years(enormous_super_big_complete_table, thresholds):
    years = enormous_super_big_complete_table['year'].unique()
    country_dict = {}

    for year in years:
        df_year, _ = filter_df(enormous_super_big_complete_table, year, thresholds)
        countries = df_year['country'].tolist()
        country_dict[year] = countries

    return country_dict

def strikes_to_dataframe(strikes):
  """Converts the strikes dictionary to a DataFrame.

  Args:
    strikes (dict): The dictionary containing consecutive year periods for each country.

  Returns:
    pd.DataFrame: A DataFrame representation of the strikes data.
  """
  all_data = []
  for country, periods in strikes.items():
    for period in periods:
      period['country'] = country
      all_data.append(period)
  return pd.DataFrame(all_data)

def get_current_PVD(conclusion, strike_size = 4):
    # Group by 'country' and sum 'length'
    length_by_country = conclusion.groupby('country')['length'].sum()

    # Get the minimum 'start_date' and maximum 'end_date' for each country
    min_max_dates = conclusion.groupby('country').agg(
        min_start_date=('start', 'min'),
        max_end_date=('end', 'max')
    )

    # Combine the results into a single DataFrame
    final_result = pd.concat([length_by_country, min_max_dates], axis=1)

    # Filter for countries where 'length' is greater than or equal to 4
    final_result = final_result[final_result['length'] >= strike_size]

    final_result.sort_values(by='length', ascending=False)

    return final_result

def plot_years_with_country(highlight, thresholds, enormous_super_big_complete_table, FROM = 2015, SEQ = 4):
    # Format the annotation text
    metric_name_map = {
        'gdp_pct_change': 'GDP Growth (%)',
        'hdi': 'HDI',
        'population_pct_change': 'Population Growth (%)',
        'per_capita_electricity': 'Energy per Capita'
    }

    # Build the metrics_text string with readable names and condition symbols
    metrics_text = "<br>".join([
        f"{metric_name_map.get(metric, metric)} {'>' if value[1] == 'bigger' else '<'} {value[0]}"
        for metric, value in thresholds.items()
    ])

    country_dict = get_countries_years(enormous_super_big_complete_table, thresholds)

    # Create a list to store the data for the plot
    plot_data = []

    # Iterate through the years and countries
    for year, countries in country_dict.items():
        if year >= 1990:  # Filter for years starting from 1990
            for country in countries:
                plot_data.append({'year': year, 'country': country})

    # Create a DataFrame from the plot data
    plot_df = pd.DataFrame(plot_data)

    # Get strikes of consecutive years in the already separated countries to plot
    strikes = calculate_consecutive_years(plot_df)
    # conclusion = calculate_consecutive_years_from(plot_df, start_date=FROM)

    # Initialize the Plotly graph object Figure
    fig = go.Figure()

    # Add scatter plot for all countries
    fig.add_trace(go.Scatter(
        x=plot_df['year'],
        y=plot_df['country'],
        mode='markers',
        marker=dict(size=10, color='blue', opacity=0.7),
        name="All Countries"
    ))

    try:
        # Filter out Senegal data
        highlight_df = plot_df[plot_df['country'] == highlight]

        # Migué
        strikes_df = strikes_to_dataframe(strikes)
        # strikes_df[strikes_df['country'] == highlight]
        conclusion = strikes_df[(strikes_df['start'] >= FROM) | ((strikes_df['end'] >= FROM) & (strikes_df['start'] <= FROM))]
        aff = conclusion[conclusion['length'] == conclusion[conclusion['country'] == highlight]['length'].max()][conclusion['country'] == highlight]


        if not aff.empty:

            # Add red line to connect Senegal points
            fig.add_trace(go.Scatter(
                x=highlight_df['year'],
                y=highlight_df['country'],
                mode='lines+markers',
                line=dict(color='red', width=3),
                marker=dict(size=10, color='red'),
                name=f"{highlight}<br>From: {int(aff['start'])} to {int(aff['end'])}<br>{int(aff['length'])} consecutive years",
            ))
        else:
            try:

                fig.add_trace(go.Scatter(
                x=highlight_df['year'],
                y=highlight_df['country'],
                mode='lines+markers',
                line=dict(color='red', width=3),
                marker=dict(size=10, color='red'),
                name=f"{highlight}",
                ))
            except:
                pass

    except:
        pass

    fig.add_annotation(
        text=f"<b>Metrics and Thresholds:</b><br>{metrics_text}",
        x=0.02,  # Relative position on the paper
        y=0.90,  # Position just under the legend
        xref="paper",  # Reference the overall paper, not the x-axis
        yref="paper",  # Reference the overall paper, not the y-axis
        xanchor="left",
        yanchor="top",
        showarrow=False,
        align="left",
        font=dict(size=12, color="black"),
        bgcolor="white",
        bordercolor="black",
        borderwidth=1
    )

    # Update layout for better presentation
    fig.update_layout(
        xaxis=dict(
            title="Year",
            showgrid=True,
            gridcolor="rgba(0, 0, 0, 0.3)",
            zeroline=True
        ),
        yaxis=dict(
            title="Country",
            showgrid=True,
            gridcolor="rgba(0, 0, 0, 0.3)"
        ),
        plot_bgcolor="white",
        paper_bgcolor="white",
        height=1300,
        width=1300,
        legend=dict(
            title="Legend",
            x=0.02,
            y=1.0,
            bordercolor="Black",
            borderwidth=1
        )
    )

    # Show the plot
    print(f"\nPlot saved to CountriesPVD.html\n")
    fig.write_html(f"CountriesPVD.html")
    fig.show()

    return plot_df, strikes, get_current_PVD(conclusion, strike_size = SEQ)

def plot_table_world_pvd(conclusion, enormous_super_big_complete_table, PREC = 3):
    # MEAN of WORLD
    aux = enormous_super_big_complete_table[(enormous_super_big_complete_table['year'] >= 1990) & (enormous_super_big_complete_table['year'] < 2022)]
    world_data_filtered = aux[aux['country']== 'World'].drop(columns=['year', 'country'])

    # Calculate the median for each column in the filtered DataFrame
    WORLD_mean = world_data_filtered.mean()

    # MEAN of PVD
    PVD = list(conclusion.index)
    aux = enormous_super_big_complete_table[(enormous_super_big_complete_table['year'] >= 1990) & (enormous_super_big_complete_table['year'] < 2022)]
    aux = aux[aux['country'].isin(PVD)].drop(columns=['year', 'country'])

    # Calculate the median for each column in the filtered DataFrame
    PVD_mean = aux.mean()

    data = {'Metric': ['hdi', 'gdp_pct_change', 'population_pct_change', 'per_capita_electricit', 'fossil_electricity', 'renewables_electricity'],
            'WORLD_mean': WORLD_mean[['hdi', 'gdp_pct_change', 'population_pct_change', 'per_capita_electricity', 'fossil_electricity', 'renewables_electricity']],
            'PVD_mean': PVD_mean[['hdi', 'gdp_pct_change', 'population_pct_change', 'per_capita_electricity', 'fossil_electricity', 'renewables_electricity']]}

    comparison_table = pd.DataFrame(data)
    better_name = {'hdi': 'HDI',
                    'gdp_pct_change': 'GDP Growth (%)',
                    'population_pct_change': 'Population Growth (%)',
                    'per_capita_electricit': 'Energy per Capita (kWh)',
                    'fossil_electricity': 'Fossil Energy (TWh)',
                    'renewables_electricity': 'Renewable Energy (TWh)'}
    comparison_table['Metric'] = comparison_table['Metric'].map(better_name)
    comparison_table = comparison_table.reset_index(drop=True)
    comparison_table.rename(columns={'WORLD_mean': 'World', 'PVD_mean': 'Developping'}, inplace=True)
    comparison_table = comparison_table.round(PREC)

    new_row = pd.DataFrame({'Metric': ['Total Countries'],
                        'World': [192],
                        'Developping': [len(PVD)]})

    # Concatenate the new row to the comparison_table DataFrame.
    comparison_table = pd.concat([comparison_table, new_row], ignore_index=True)

    HEADER = 25
    TEXT = 18
    fig = go.Figure(data=[go.Table(
        header=dict(
            values=list(comparison_table.columns),
            fill_color='lightblue',
            align='center',  # Centralizando os títulos
            line_color='gray',  # Linha separando as colunas
            line_width=1,  # Largura da linha
            font=dict(size=HEADER),
            height=1.5*HEADER
        ),
        cells=dict(
            values=[comparison_table.Metric, comparison_table.World, comparison_table.Developping],
            fill_color='white',
            align='center',  # Centralizando os valores
            line_color='gray',  # Linha separando as células
            line_width=1,  # Largura da linha
            font=dict(size=TEXT),
            height=1.5*TEXT
        )
    )])

    # Ajustando o título e centralizando-o
    fig.update_layout(title = 'Comparison of World and Developping Countries (mean from 1990 to 2021)',
                    title_x=0.5,  # Centralizando o título
                    width=12*HEADER*len(comparison_table.columns),  # Ajustando o tamanho do gráfico
                    height=3.5*TEXT*len(comparison_table))  # Ajustando a altura do gráfico



    fig.show()

def download_excel_data(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for bad status codes

        # Use pandas to read the Excel file directly from the content
        df = pd.read_excel(response.content)
        return df
    except requests.exceptions.RequestException as e:
        print(f"Error downloading Excel data: {e}")
        return None
    except Exception as e:
        print(f"Error processing Excel data: {e}")
        return None
